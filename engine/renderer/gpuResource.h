#ifndef GPU_RESOURCE_H_
#define GPU_RESOURCE_H_

#include "common.h"

namespace vkl {
enum BufferUsageFlagBits {
    BUFFER_USAGE_TRANSFER_SRC_BIT          = 0x00000001,
    BUFFER_USAGE_TRANSFER_DST_BIT          = 0x00000002,
    BUFFER_USAGE_UNIFORM_TEXEL_BUFFER_BIT  = 0x00000004,
    BUFFER_USAGE_STORAGE_TEXEL_BUFFER_BIT  = 0x00000008,
    BUFFER_USAGE_UNIFORM_BUFFER_BIT        = 0x00000010,
    BUFFER_USAGE_STORAGE_BUFFER_BIT        = 0x00000020,
    BUFFER_USAGE_INDEX_BUFFER_BIT          = 0x00000040,
    BUFFER_USAGE_VERTEX_BUFFER_BIT         = 0x00000080,
    BUFFER_USAGE_INDIRECT_BUFFER_BIT       = 0x00000100,
    BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT = 0x00020000,
    BUFFER_USAGE_FLAG_BITS_MAX_ENUM        = 0x7FFFFFFF
};
using BufferUsageFlags = uint32_t;

enum MemoryPropertyFlagBits {
    MEMORY_PROPERTY_DEVICE_LOCAL_BIT        = 0x00000001,
    MEMORY_PROPERTY_HOST_VISIBLE_BIT        = 0x00000002,
    MEMORY_PROPERTY_HOST_COHERENT_BIT       = 0x00000004,
    MEMORY_PROPERTY_HOST_CACHED_BIT         = 0x00000008,
    MEMORY_PROPERTY_LAZILY_ALLOCATED_BIT    = 0x00000010,
    MEMORY_PROPERTY_PROTECTED_BIT           = 0x00000020,
    MEMORY_PROPERTY_DEVICE_COHERENT_BIT_AMD = 0x00000040,
    MEMORY_PROPERTY_DEVICE_UNCACHED_BIT_AMD = 0x00000080,
    MEMORY_PROPERTY_RDMA_CAPABLE_BIT_NV     = 0x00000100,
    MEMORY_PROPERTY_FLAG_BITS_MAX_ENUM      = 0x7FFFFFFF
};
using MemoryPropertyFlags = uint32_t;

struct BufferCreateInfo {
    uint32_t            size      = 0;
    uint32_t            alignment = 0;
    BufferUsageFlags    usage;
    MemoryPropertyFlags property;
};
}

#endif // RESOURCE_H_
